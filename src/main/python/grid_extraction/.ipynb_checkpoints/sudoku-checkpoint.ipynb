{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR0n1T1ugMpy"
   },
   "source": [
    "# Sudoku Detector\n",
    "\n",
    "Author: [Egor Makarenko](https://github.com/egormkn)\n",
    "\n",
    "Neural sudoku detection and extraction tool based on Tensorflow [image segmentation tutorial](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/images/segmentation.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "cHVSymX3DaXa",
    "outputId": "5938e5bc-fc12-4a40-e1d8-e227e72d5682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'google.colab', skipping Google Drive mount\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "  from google.colab import drive\n",
    "  drive.mount('/content/drive')\n",
    "except ImportError as e:\n",
    "  print(f'{e}, skipping Google Drive mount')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "gB9NEU3cHomj",
    "outputId": "cd19600c-4824-46d4-e3eb-4d9b93c1969f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'drive/My Drive/sudoku'\n",
      "/home/egor/Documents/sudoku\n"
     ]
    }
   ],
   "source": [
    "%cd drive/My\\ Drive/sudoku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "hJXbIEOPIBiF",
    "outputId": "223ebdf2-83ea-4b54-f98e-03d62a021356"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8evGraJztdB2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import skimage\n",
    "import sklearn\n",
    "import itertools\n",
    "import collections\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from os import listdir, path\n",
    "from skimage import draw, io\n",
    "from more_itertools import grouper\n",
    "from IPython.display import clear_output\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFont, ImageOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "bBmbkUsYCfCf",
    "outputId": "030293de-b589-473b-e010-d77d6caf4b6b"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(f'Physical GPUs: {len(gpus)}, Logical GPUs: {len(logical_gpus)}')\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y3dpLIkK6S-x"
   },
   "outputs": [],
   "source": [
    "def show_images(images, figsize=(15, 15)):\n",
    "  plt.figure(figsize=figsize)\n",
    "  for index, (title, image) in enumerate(images.items()):\n",
    "    if len(image.shape) == 3 and image.shape[2] == 1:\n",
    "      image = np.squeeze(image, axis=2)\n",
    "    plt.subplot(1, len(images), index + 1)\n",
    "    plt.title(title)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2TxNmnSPebqy"
   },
   "source": [
    "### Sudoku puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o_lWQfP55WEA"
   },
   "outputs": [],
   "source": [
    "class Sudoku:\n",
    "\n",
    "  known = 0\n",
    "  puzzle = None\n",
    "  solution = None\n",
    "    \n",
    "  def pluck(self, puzzle, n=0):\n",
    "    def canBeA(puz, i, j, c):\n",
    "      i, j = int(i), int(j)\n",
    "      v = puz[c // 9][c % 9]\n",
    "      if puz[i][j] == v: return True\n",
    "      if puz[i][j] in range(1, 10): return False\n",
    "      for m in range(9):\n",
    "        if not (m == c // 9 and j == c % 9) and puz[m][j] == v: return False\n",
    "        if not (i == c // 9 and m == c % 9) and puz[i][m] == v: return False\n",
    "        if not ((i // 3) * 3 + m // 3 == c // 9 and (j // 3) * 3 + m % 3 == c % 9) \\\n",
    "          and puz[(i // 3) * 3 + m // 3][(j // 3) * 3 + m % 3] == v:\n",
    "          return False\n",
    "      return True\n",
    "\n",
    "    cells     = set(range(81))\n",
    "    cellsleft = cells.copy()\n",
    "    while len(cells) > n and len(cellsleft):\n",
    "      cell = random.choice(list(cellsleft))\n",
    "      cellsleft.discard(cell)\n",
    "      row = col = square = False\n",
    "\n",
    "      for i in range(9):\n",
    "        if i != cell / 9:\n",
    "          if canBeA(puzzle, i, cell%9, cell): row = True\n",
    "        if i != cell % 9:\n",
    "          if canBeA(puzzle, cell/9, i, cell): col = True\n",
    "        if not (((cell // 9) // 3) * 3 + i // 3 == cell // 9 and ((cell // 9) % 3) * 3 + i % 3 == cell % 9):\n",
    "          if canBeA(puzzle, ((cell // 9) // 3) * 3 + i // 3, ((cell // 9) % 3) * 3 + i % 3, cell): square = True\n",
    "\n",
    "      if row and col and square:\n",
    "        continue\n",
    "      else:\n",
    "        puzzle[cell // 9][cell % 9] = 0\n",
    "        cells.discard(cell)\n",
    "\n",
    "    return len(cells), puzzle\n",
    "  \n",
    "  def generate_puzzle(self, n=40, iterations=100):\n",
    "    results = {}\n",
    "    for i in range(iterations):\n",
    "      puzzle = [row.copy() for row in self.solution]\n",
    "      cells, puzzle = self.pluck(puzzle, n)\n",
    "      results.setdefault(cells, []).append(puzzle)\n",
    "      if cells <= n: break\n",
    "    least_known = min(results.keys())\n",
    "    return least_known, results[least_known][0]\n",
    "  \n",
    "  def generate_solution(self):\n",
    "    while True:\n",
    "      solution = [[0] * 9 for _ in range(9)]\n",
    "      error    = False\n",
    "      rows     = [set(range(1, 10)) for _ in range(9)]\n",
    "      columns  = [set(range(1, 10)) for _ in range(9)]\n",
    "      squares  = [set(range(1, 10)) for _ in range(9)]\n",
    "      for i in range(9):\n",
    "        for j in range(9):\n",
    "          row, column, square = rows[i], columns[j], squares[(i // 3) * 3 + j // 3]\n",
    "          choices = row.intersection(column).intersection(square)\n",
    "          error = not(choices)\n",
    "          if error: break\n",
    "          choice  = random.choice(list(choices))\n",
    "          solution[i][j] = choice\n",
    "          row.discard(choice)\n",
    "          column.discard(choice)\n",
    "          square.discard(choice)\n",
    "        if error: break\n",
    "      if not error: return solution\n",
    "  \n",
    "  def __init__(self, known=40, iterations=100):\n",
    "    self.solution = self.generate_solution()\n",
    "    self.known, self.puzzle = self.generate_puzzle(known, iterations)\n",
    "\n",
    "  def image(self, size=(512, 512), padding=12, bgcolor='white', linecolor='green', \n",
    "           linewidth=(1, 3), font=None, fontsize=30, fontcolor='red'):\n",
    "    image = Image.new('RGBA', size, color='#00000000')\n",
    "    font  = ImageFont.truetype(font, fontsize) if font else ImageFont.load_default()\n",
    "    draw  = ImageDraw.Draw(image)\n",
    "    \n",
    "    width, height = size\n",
    "    \n",
    "    cell_width, cell_height = (np.asarray(size) - 2 * padding) / 9\n",
    "    \n",
    "    draw.rectangle((padding, padding, width - padding, height - padding), fill=bgcolor)\n",
    "    \n",
    "    for i in range(10):\n",
    "      x_pos = padding + cell_width * i\n",
    "      y_pos = padding + cell_height * i\n",
    "      draw.line((padding, y_pos, width - padding, y_pos),  fill=linecolor, width=linewidth[i % 3 == 0])\n",
    "      draw.line((x_pos, padding, x_pos, height - padding), fill=linecolor, width=linewidth[i % 3 == 0])\n",
    "    \n",
    "    for x in range(9):\n",
    "      for y in range(9):\n",
    "        if not self.puzzle[y][x]: continue\n",
    "        x_pos = padding + cell_width * x\n",
    "        y_pos = padding + cell_height * y\n",
    "        text = str(self.puzzle[y][x])\n",
    "        text_width, text_height = draw.textsize(text, font)\n",
    "        text_pos = (x_pos + (cell_width - text_width) / 2, y_pos + (cell_height - text_height) / 2)\n",
    "        draw.text(text_pos, text, fontcolor, font)\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "KZfuynJQ6bGc",
    "outputId": "8ce3118a-92c2-4825-863d-fcb2b5b101b3"
   },
   "outputs": [],
   "source": [
    "sudoku = Sudoku(20)\n",
    "print(f'Known values: {sudoku.known}')\n",
    "sudoku.puzzle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177
    },
    "colab_type": "code",
    "id": "jTdApZnEA7CL",
    "outputId": "cb653df5-3e4f-44b8-96c1-00cdd3514fc6"
   },
   "outputs": [],
   "source": [
    "sudoku.solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 529
    },
    "colab_type": "code",
    "id": "T8-WVutUJU3Z",
    "outputId": "6836e74e-f8e1-4bd4-f371-1f001fc35e73"
   },
   "outputs": [],
   "source": [
    "sudoku.image(font='fonts/arial.ttf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_U5ojzttebrW"
   },
   "source": [
    "### Sudoku generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5qrjck1yUfF8"
   },
   "outputs": [],
   "source": [
    "def sudoku_generator(include_data=True, **kwargs):\n",
    "  fonts = glob.glob(path.join('fonts', '*.ttf'))\n",
    "  backgrounds = glob.glob(path.join('backgrounds', '*.jpg'))\n",
    "  width, height = 512, 512\n",
    "  padding = 12\n",
    "  shift = lambda x: int(random.triangular(0, (x - 2 * padding), 0) / 9)\n",
    "  \n",
    "  while True:\n",
    "    bgcolor = tuple(int(random.triangular(220, 255, 255))  for _ in range(3))\n",
    "    linecolor = tuple(random.randint(0, 50) for _ in range(3))\n",
    "    linewidth = random.randint(1, 5)\n",
    "    linewidth = (linewidth, linewidth + random.randint(0, 5))\n",
    "    font = random.choice(fonts)\n",
    "    fontsize = random.randint(25, 35)\n",
    "    fontcolor = f'hsl({random.randint(0, 360)}, 100%, {int(random.triangular(0, 50, 10))}%)'\n",
    "    fill = random.random() * 0.8\n",
    "    bg_image = random.choice(backgrounds)\n",
    "    bg_image = Image.open(bg_image).convert('RGBA')\n",
    "    bg_width, bg_height = bg_image.size\n",
    "\n",
    "    sudoku = Sudoku(known=random.randint(40, 60))\n",
    "    data = sudoku.puzzle\n",
    "    image = sudoku.image(size=(width, height), padding=padding, bgcolor=bgcolor, linecolor=linecolor, \n",
    "                         linewidth=linewidth, font=font, fontcolor=fontcolor, fontsize=fontsize, **kwargs)\n",
    "\n",
    "    polygon = np.asarray([\n",
    "      [         padding,         padding], \n",
    "      [         padding, width - padding], \n",
    "      [height - padding, width - padding], \n",
    "      [height - padding,         padding]\n",
    "    ])\n",
    "\n",
    "    distortion = np.asarray([\n",
    "      [ shift(height),  shift(width)],\n",
    "      [ shift(height), -shift(width)],\n",
    "      [-shift(height), -shift(width)],\n",
    "      [-shift(height),  shift(width)]\n",
    "    ])\n",
    "    \n",
    "    coeffs = cv2.getPerspectiveTransform(\n",
    "      np.float32(polygon + distortion), \n",
    "      np.float32(polygon)\n",
    "    ).flatten()[:8]\n",
    "    \n",
    "    bg_coeffs = cv2.getPerspectiveTransform(\n",
    "      np.float32((polygon + distortion) / [height, width] * [bg_height, bg_width]), \n",
    "      np.float32([[0, 0], [0, bg_width - 1], [bg_height - 1, bg_width - 1], [bg_height - 1, 0]])\n",
    "    ).flatten()[:8]\n",
    "    \n",
    "    extend = random.randint(0, max(width, height))\n",
    "    crop_w, crop_h = random.randint(0, extend), random.randint(0, extend)\n",
    "    \n",
    "    image = image.transform(image.size, Image.PERSPECTIVE, coeffs, Image.BICUBIC)\n",
    "    bg_image = bg_image.transform(bg_image.size, Image.PERSPECTIVE, bg_coeffs, Image.BICUBIC)\n",
    "    image = image.crop((-crop_w, -crop_h, width + (extend - crop_w), height + (extend - crop_h)))\n",
    "    image = image.resize((width, height))\n",
    "    polygon = (polygon + distortion + [crop_w, crop_h]) / [width + extend, height + extend] * [width, height]\n",
    "    bg_image = bg_image.crop((bg_width * 0.2, bg_height * 0.2, bg_width * 0.8, bg_height * 0.8))\n",
    "    bg_image = bg_image.resize(image.size)\n",
    "    \n",
    "    image = Image.alpha_composite(bg_image, image).convert('RGB')\n",
    "\n",
    "    image = np.uint8(image)\n",
    "    polygon = np.flip(polygon, axis=1).astype(np.int32)\n",
    "\n",
    "    yield (image, polygon, data) if include_data else (image, polygon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ms75XOjlebrh"
   },
   "outputs": [],
   "source": [
    "def is_grayscale(image):\n",
    "  return len(image.shape) < 3 or image.shape[2] == 1\n",
    "\n",
    "def draw_polygon(image, polygon, color='#FF00FF', radius=None):\n",
    "  color = ImageColor.getrgb(color)\n",
    "  if image.dtype == np.float32:\n",
    "    color = np.asarray(color) / 255.0\n",
    "  if not radius:\n",
    "    radius = max(*image.shape[:2]) // 50\n",
    "  if is_grayscale(image):\n",
    "    image = np.concatenate((image,)*3, axis=-1)\n",
    "  else:\n",
    "    image = np.copy(image)\n",
    "  rr, cc = skimage.draw.polygon_perimeter(polygon[:, 0], polygon[:, 1], shape=image.shape, clip=True)\n",
    "  image[rr, cc] = color\n",
    "  for r, c in polygon:\n",
    "    rr, cc = skimage.draw.circle(r, c, radius)\n",
    "    rr = np.clip(rr, 0, image.shape[0] - 1)\n",
    "    cc = np.clip(cc, 0, image.shape[1] - 1)\n",
    "    image[rr, cc] = color\n",
    "  return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ad9VBqsyfLEb"
   },
   "source": [
    "### Sudoku photos\n",
    "Source: https://github.com/wichtounet/sudoku_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "colab_type": "code",
    "id": "tADVmsjwae4f",
    "outputId": "ef905d9a-dc30-435d-e972-bc9d74b2514b"
   },
   "outputs": [],
   "source": [
    "def convert_row(row):\n",
    "  filepath = path.normpath(path.join('sudoku_dataset', row.filepath))\n",
    "  polygon = [\n",
    "    [row.p1_y, row.p1_x], \n",
    "    [row.p2_y, row.p2_x], \n",
    "    [row.p3_y, row.p3_x], \n",
    "    [row.p4_y, row.p4_x]\n",
    "  ]\n",
    "  m_y = (row.p1_y + row.p2_y + row.p3_y + row.p4_y) / 4\n",
    "  m_x = (row.p1_x + row.p2_x + row.p3_x + row.p4_x) / 4\n",
    "  assert row.p1_y < m_y and row.p1_x < m_x\n",
    "  assert row.p2_y < m_y and row.p2_x > m_x\n",
    "  assert row.p3_y > m_y and row.p3_x > m_x\n",
    "  assert row.p4_y > m_y and row.p4_x < m_x\n",
    "  return pd.Series([filepath, polygon], index=['filepath', 'polygon'])\n",
    "\n",
    "df = pd.read_csv(path.join('sudoku_dataset', 'outlines_sorted.csv')).apply(convert_row, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gFJrPoDT2n79"
   },
   "outputs": [],
   "source": [
    "paths, polygons = df['filepath'].tolist(), df['polygon'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n3yl6NKPebsC"
   },
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6qiekiJEebsD",
    "outputId": "63ebd87e-117b-4e29-ac94-91a0c5dd1dca"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess_github(path, polygon):\n",
    "  image = tf.io.read_file(path)\n",
    "  image = tf.io.decode_image(image, channels=3, expand_animations=False, dtype=tf.uint8)\n",
    "  image.set_shape((None, None, 3))\n",
    "  return image, polygon\n",
    "\n",
    "github_dataset = tf.data.Dataset.from_tensor_slices((paths, polygons)).map(preprocess_github, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "github_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8lGyuIEKqLZL",
    "outputId": "3c5a6caf-1811-4d51-8f0e-d7f5dfac57f3"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess_generated(image, polygon):\n",
    "  image.set_shape((None, None, 3))\n",
    "  polygon.set_shape((4, 2))\n",
    "  return image, polygon\n",
    "\n",
    "generated_dataset = tf.data.Dataset.from_generator(sudoku_generator, output_types=(tf.uint8, tf.int32), args=[False]).map(preprocess_generated, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "generated_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "colab_type": "code",
    "id": "kpTMmps5ebsT",
    "outputId": "9f0f7856-6129-4d85-ad19-d0a677ab6ec6"
   },
   "outputs": [],
   "source": [
    "for (i1, p1), (i2, p2) in tf.data.Dataset.zip((github_dataset, generated_dataset)).take(1):\n",
    "  show_images({\n",
    "    'Github dataset': draw_polygon(i1, p1),\n",
    "    'Generated dataset': draw_polygon(i2, p2)\n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I6OyAsp9ebsc"
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "PSY5hGDnebsd",
    "outputId": "76f63b98-b6b2-4bc6-f434-d01da26cdd90"
   },
   "outputs": [],
   "source": [
    "APPLY_THRESHOLD = True\n",
    "IMAGE_SIZE = 224\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "def preprocess_image(image):\n",
    "  colored = not(is_grayscale(image))\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if colored else np.squeeze(image, axis=2)\n",
    "  image = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 21, 3)\n",
    "  image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB) if colored else np.expand_dims(image, axis=2)\n",
    "  return image\n",
    "\n",
    "def preprocess_polygon(image, polygon):\n",
    "  height, width = image.shape[:2]\n",
    "  scale = IMAGE_SIZE / max(height, width)\n",
    "  shift = abs(height - width) / 2 * scale * np.array([0, 1] if height > width else [1, 0])\n",
    "  return (polygon * scale + shift).astype(np.int32)\n",
    "\n",
    "@tf.function\n",
    "def preprocess(image, polygon):\n",
    "  polygon = tf.numpy_function(preprocess_polygon, [image, polygon], Tout=tf.int32)\n",
    "  image = tf.cast(tf.image.resize_with_pad(image, IMAGE_SIZE, IMAGE_SIZE), tf.uint8)\n",
    "  \n",
    "  if IMAGE_CHANNELS == 1:\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    if APPLY_THRESHOLD:\n",
    "      image = tf.numpy_function(preprocess_image, [image], Tout=tf.uint8)\n",
    "  \n",
    "  image.set_shape((IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "  polygon.set_shape((4, 2))\n",
    "  \n",
    "  return image, polygon\n",
    "\n",
    "polygon_dataset = tf.data.experimental.sample_from_datasets([github_dataset, generated_dataset]).map(preprocess, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "polygon_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "sFTq_0bWebsj",
    "outputId": "edb08440-f838-44a0-c166-036dcaa14d9a"
   },
   "outputs": [],
   "source": [
    "show_images({ \n",
    "  f'Image {i}': draw_polygon(image, polygon) for i, (image, polygon) in enumerate(polygon_dataset.take(3)) \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "98r0BvuUebss"
   },
   "source": [
    "### Convert polygons to masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8Z2VdPeFMOlg",
    "outputId": "8224681e-0cdc-48f0-8f4f-fbf355a6f95e"
   },
   "outputs": [],
   "source": [
    "def create_mask(image, polygon):\n",
    "  shape = (*image.shape[:2], 1)\n",
    "  mask = np.zeros(shape, dtype=np.bool)\n",
    "  rr, cc = skimage.draw.polygon(polygon[:, 0], polygon[:, 1], shape)\n",
    "  mask[rr, cc] = True\n",
    "  return mask\n",
    "\n",
    "def draw_mask(image, mask):\n",
    "  return np.where(mask, image, 0)\n",
    "\n",
    "@tf.function\n",
    "def apply_mask(image, polygon):\n",
    "  mask = tf.numpy_function(create_mask, [image, polygon], Tout=tf.bool)\n",
    "  mask.set_shape(((IMAGE_SIZE, IMAGE_SIZE, 1)))\n",
    "  return image, mask\n",
    "\n",
    "mask_dataset = polygon_dataset.map(apply_mask, num_parallel_calls=tf.data.experimental.AUTOTUNE, deterministic=False)\n",
    "mask_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 837
    },
    "colab_type": "code",
    "id": "EYn26uIPebs2",
    "outputId": "f34bbbeb-321a-4f3e-f451-55feb3262539"
   },
   "outputs": [],
   "source": [
    "for image, mask in mask_dataset.take(2):\n",
    "  show_images({ \n",
    "    'Image': image,\n",
    "    'Image + Mask': draw_mask(image, mask)  \n",
    "  })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2opebLw6ebtI"
   },
   "source": [
    "### Preparing train and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XF6PMv47JpDV",
    "outputId": "632c6d80-17a9-447c-9855-ec7b675edd7f"
   },
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 5000\n",
    "TEST_SIZE = 100\n",
    "BATCH_SIZE = 50\n",
    "BUFFER_SIZE = 50\n",
    "USE_MASKS = True\n",
    "\n",
    "def draw_output(image, output):\n",
    "  return draw_polygon(image, output) if output.shape == (4, 2) else draw_mask(image, output)\n",
    "\n",
    "def augment_mask(image, mask):\n",
    "  mask.set_shape((IMAGE_SIZE, IMAGE_SIZE, 1))\n",
    "  return image, mask\n",
    "\n",
    "def augment_polygon(image, polygon):\n",
    "  polygon.set_shape((4, 2))\n",
    "  return image, polygon\n",
    "\n",
    "@tf.function\n",
    "def augment(image, output):\n",
    "  image = tf.image.random_jpeg_quality(image, 70, 100)\n",
    "  image, output = augment_mask(image, output) if USE_MASKS else augment_polygon(image, output)\n",
    "  image.set_shape((IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS))\n",
    "  return image, output\n",
    "\n",
    "dataset = mask_dataset if USE_MASKS else polygon_dataset\n",
    "\n",
    "train_dataset = dataset.take(TRAIN_SIZE).map(augment, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = dataset.skip(TRAIN_SIZE).take(TEST_SIZE)\n",
    "\n",
    "for image, output in train_dataset.take(5):\n",
    "  sample_image, sample_output = image, output\n",
    "  show_images({ 'Image': image, 'Output': draw_output(image, output) })\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat().prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
    "print(f'Train dataset: {train_dataset}')\n",
    "print(f'Test dataset: {test_dataset}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E355c5m8KSbW"
   },
   "source": [
    "### Model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6SEr7sSaI3FG"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Upsamples an input.\n",
    "Conv2DTranspose => Batchnorm => Dropout => Relu\n",
    "Args:\n",
    "filters: number of filters\n",
    "size: filter size\n",
    "norm_type: Normalization type; either 'batchnorm' or 'instancenorm'.\n",
    "apply_dropout: If True, adds the dropout layer\n",
    "Returns:\n",
    "Upsample Sequential Model\n",
    "\"\"\"\n",
    "def pix2pix_upsample(filters, size, norm_type='batchnorm', apply_dropout=False):\n",
    "  initializer = tf.random_normal_initializer(0., 0.02)\n",
    "\n",
    "  result = tf.keras.Sequential()\n",
    "  result.add(\n",
    "      tf.keras.layers.Conv2DTranspose(filters, size, strides=2, padding='same',\n",
    "                                      kernel_initializer=initializer,\n",
    "                                      use_bias=False))\n",
    "\n",
    "  if norm_type.lower() == 'batchnorm':\n",
    "    result.add(tf.keras.layers.BatchNormalization())\n",
    "  elif norm_type.lower() == 'instancenorm':\n",
    "    result.add(InstanceNormalization())\n",
    "\n",
    "  if apply_dropout:\n",
    "    result.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "  result.add(tf.keras.layers.ReLU())\n",
    "\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilenet = tf.keras.applications.MobileNetV2(input_shape=[IMAGE_SIZE, IMAGE_SIZE, IMAGE_CHANNELS], include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G6h_-r2yNjQb"
   },
   "outputs": [],
   "source": [
    "def unet_model(output_channels):\n",
    "  # Use the activations of these layers\n",
    "  layer_names = [\n",
    "    'block_1_expand_relu',   # 112x112\n",
    "    'block_3_expand_relu',   # 56x56\n",
    "    'block_6_expand_relu',   # 28x28\n",
    "    'block_13_expand_relu',  # 14x14\n",
    "    'block_16_project',      # 7x7\n",
    "  ]\n",
    "  layers = [mobilenet.get_layer(name).output for name in layer_names]\n",
    "\n",
    "  # Create the feature extraction model\n",
    "  down_stack = tf.keras.Model(inputs=mobilenet.input, outputs=layers)\n",
    "  down_stack.trainable = False\n",
    "\n",
    "  # Create the upsampling model\n",
    "  up_stack = [\n",
    "      pix2pix_upsample(512, 3),  # 7x7   -> 14x14\n",
    "      pix2pix_upsample(256, 3),  # 14x14 -> 28x28\n",
    "      pix2pix_upsample(128, 3),  # 28x28 -> 56x56\n",
    "      pix2pix_upsample(64, 3),   # 56x56 -> 112x112\n",
    "  ]\n",
    "  \n",
    "  inputs = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], dtype = tf.uint8)\n",
    "  x = tf.cast(inputs, tf.float32)\n",
    "  x = tf.keras.applications.mobilenet.preprocess_input(x)\n",
    "  \n",
    "  # Downsampling through the model\n",
    "  skips = down_stack(x)\n",
    "  x = skips[-1]\n",
    "  skips = reversed(skips[:-1])\n",
    "\n",
    "  # Upsampling and establishing the skip connections\n",
    "  for up, skip in zip(up_stack, skips):\n",
    "    x = up(x)\n",
    "    concat = tf.keras.layers.Concatenate()\n",
    "    x = concat([x, skip])\n",
    "\n",
    "  # This is the last layer of the model\n",
    "  last = tf.keras.layers.Conv2DTranspose(\n",
    "      output_channels, 3, strides=2,\n",
    "      padding='same')\n",
    "\n",
    "  x = last(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "mask_model = unet_model(OUTPUT_CHANNELS)\n",
    "mask_model.compile(optimizer='adam',\n",
    "                   loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "mask_model.summary()\n",
    "tf.keras.utils.plot_model(mask_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zhl22tk8ebtt"
   },
   "outputs": [],
   "source": [
    "def custom_model(output_channels):\n",
    "  inputs = tf.keras.layers.Input(shape=[IMAGE_SIZE, IMAGE_SIZE, 3], dtype = tf.uint8)\n",
    "  x = tf.cast(inputs, tf.float32)\n",
    "  x = tf.keras.applications.mobilenet.preprocess_input(x)\n",
    "\n",
    "  # Downsampling through the model\n",
    "  skips = down_stack(x)\n",
    "  x = skips[-1]\n",
    "  \n",
    "  x = tf.keras.layers.Conv2D(10, (1, 1), activation='relu')(x)\n",
    "  x = tf.keras.layers.Flatten()(x)\n",
    "  x = tf.keras.layers.Dense(128)(x)\n",
    "  x = tf.keras.layers.Dense(8)(x)\n",
    "  x = tf.keras.layers.Reshape((4, 2))(x)\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "polygon_model = unet_model(OUTPUT_CHANNELS)\n",
    "polygon_model.compile(optimizer='adam',\n",
    "                   loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "                   metrics=['accuracy'])\n",
    "polygon_model.summary()\n",
    "tf.keras.utils.plot_model(polygon_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mask_model if USE_MASKS else polygon_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UzLhrJkhN844"
   },
   "outputs": [],
   "source": [
    "def show_predictions(dataset=None, num=1):\n",
    "  if dataset:\n",
    "    for image, output in dataset.take(num):\n",
    "      prediction = model.predict(image)\n",
    "      show_images({ 'Image': image, 'Mask': output, 'Prediction': draw_output(image, prediction[0]) })\n",
    "  else:\n",
    "    prediction = model.predict(sample_image[tf.newaxis, ...])\n",
    "    show_images({ 'Image': sample_image, 'Mask': sample_output, 'Prediction': draw_output(image, prediction[0]) })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "aT8WAgzYDRqy",
    "outputId": "0283d9e5-03f8-42b5-f7d2-82b78c309eb8"
   },
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "38BKijAnOiZx"
   },
   "outputs": [],
   "source": [
    "class InfoCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    print(f'\\nEpoch {epoch+1} ended. Preparing prediction')\n",
    "    # clear_output(wait=True)\n",
    "    show_predictions()\n",
    "    \n",
    "class EnoughCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy') > 0.9999):\n",
    "      print('\\nReached 99% accuracy so stopping training!')\n",
    "      self.model.stop_training = True\n",
    "\n",
    "info_callback = InfoCallback()\n",
    "enough_callback = EnoughCallback()\n",
    "\n",
    "model_weights_dir = path.join('checkpoints', 'mask' if USE_MASKS else 'polygon')\n",
    "model_weights = path.join(model_weights_dir, 'model-{epoch:04d}.ckpt')\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(filepath=model_weights, save_weights_only=True, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "id": "aAUTvYf6Okkw",
    "outputId": "73cb5c5b-aff9-4393-b132-b504f8d26fb3"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "STEPS_PER_EPOCH = TRAIN_SIZE // BATCH_SIZE\n",
    "VALIDATION_STEPS = TEST_SIZE // BATCH_SIZE\n",
    "\n",
    "print(f'Train size: {TRAIN_SIZE}, test size: {TEST_SIZE}')\n",
    "print(f'BATCH_SIZE = {BATCH_SIZE}, VALIDATION_STEPS = {VALIDATION_STEPS}, STEPS_PER_EPOCH = {STEPS_PER_EPOCH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "sZkZxPoeDPEj",
    "outputId": "efa1b774-6dfe-470d-ad31-845fa486b5b9"
   },
   "outputs": [],
   "source": [
    "if path.exists(model_weights_dir):\n",
    "  checkpoint = tf.train.latest_checkpoint(model_weights_dir)\n",
    "  model.load_weights(checkpoint)\n",
    "  print(f'Loaded checkpoint: {checkpoint}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RmohGKo1ebuk"
   },
   "outputs": [],
   "source": [
    "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
    "                          steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                          validation_steps=VALIDATION_STEPS,\n",
    "                          validation_data=test_dataset,\n",
    "                          callbacks=[save_callback, info_callback, enough_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6osRnxD9Pr95"
   },
   "outputs": [],
   "source": [
    "loss = model_history.history['loss']\n",
    "val_loss = model_history.history['val_loss']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xH0XDZj0BMQS"
   },
   "outputs": [],
   "source": [
    "accuracy = model_history.history['accuracy']\n",
    "val_accuracy = model_history.history['val_accuracy']\n",
    "\n",
    "epochs = range(EPOCHS)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, accuracy, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, 'bo', label='Validation accuracy')\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Value')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 612
    },
    "colab_type": "code",
    "id": "c4SRyMRYPvKd",
    "outputId": "a4b45d34-565c-4086-a0d3-e9855768e9a6"
   },
   "outputs": [],
   "source": [
    "show_predictions(test_dataset, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PnSKEa-qcs-T"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "\n",
    "uploaded = files.upload()\n",
    "\n",
    "for filename, content in uploaded.items():\n",
    "  image = tf.constant(content)\n",
    "  image = tf.io.decode_image(image, channels=3, expand_animations=False)\n",
    "  image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n",
    "  image = tf.image.resize_with_pad(image, IMAGE_SIZE, IMAGE_SIZE, antialias=True)\n",
    "\n",
    "  pred_mask = model.predict(image[tf.newaxis, ...])\n",
    "  show_images({'Image': image, 'Prediction': pred_mask[0]})\n",
    "\n",
    "  mask = minmax_scale(pred_mask[0].squeeze(), feature_range=(0, 255))\n",
    "\n",
    "  plt.imshow(mask, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErLr9l0KsDH0"
   },
   "outputs": [],
   "source": [
    "sample_prediction = model.predict(sample_image)\n",
    "sample_prediction = tf.keras.preprocessing.image.array_to_img(sample_prediction[0])\n",
    "sample_prediction.save('prediction.png')\n",
    "plt.imshow(sample_prediction, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AtZVBnBasVBf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "sudoku.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "python3.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
