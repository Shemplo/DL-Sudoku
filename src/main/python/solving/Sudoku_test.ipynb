{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sudoku_test.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBGK85E_YxhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "452f43b9-4b55-46b3-f2f8-0dd7b6630855"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "%autosave 100"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.set_autosave_interval(100000)"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Autosaving every 100 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hNn-RJ98ZPpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7rZPsnrZ_f6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "13592467-8fa2-494f-eba7-d2addeb4d51f"
      },
      "source": [
        "quizes = np.empty((30, 81), np.float32)\n",
        "solutions = np.empty((30, 81), np.int64)\n",
        "\n",
        "i=0\n",
        "f = open(\"/content/drive/My Drive/Colab Notebooks/sudoku_test.csv\")\n",
        "for line in f:\n",
        "    quiz, solution = line.strip().split(\",\")\n",
        "    quizes[i] = [int(i) for i in quiz]\n",
        "    solutions[i] = [int(i) for i in solution]\n",
        "    i += 1\n",
        "\n",
        "quizes = quizes.reshape((-1, 9, 9))\n",
        "solutions = solutions.reshape((-1, 9, 9))\n",
        "\n",
        "print(\"quizes\\n\", quizes[0])\n",
        "print(\"solutions\\n\", solutions[0])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "quizes\n",
            " [[0. 8. 0. 0. 3. 2. 0. 0. 1.]\n",
            " [7. 0. 3. 0. 8. 0. 0. 0. 2.]\n",
            " [5. 0. 0. 0. 0. 7. 0. 3. 0.]\n",
            " [0. 5. 0. 0. 0. 1. 9. 7. 0.]\n",
            " [6. 0. 0. 7. 0. 9. 0. 0. 8.]\n",
            " [0. 4. 7. 2. 0. 0. 0. 5. 0.]\n",
            " [0. 2. 0. 6. 0. 0. 0. 0. 9.]\n",
            " [8. 0. 0. 0. 9. 0. 3. 0. 5.]\n",
            " [3. 0. 0. 8. 2. 0. 0. 1. 0.]]\n",
            "solutions\n",
            " [[4 8 9 5 3 2 7 6 1]\n",
            " [7 1 3 4 8 6 5 9 2]\n",
            " [5 6 2 9 1 7 8 3 4]\n",
            " [2 5 8 3 4 1 9 7 6]\n",
            " [6 3 1 7 5 9 2 4 8]\n",
            " [9 4 7 2 6 8 1 5 3]\n",
            " [1 2 5 6 7 3 4 8 9]\n",
            " [8 7 6 1 9 4 3 2 5]\n",
            " [3 9 4 8 2 5 6 1 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DCWyU01ZdxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, c_in, c_out, filt=3, stride=1, padding=1):\n",
        "    super(ConvNet, self).__init__()\n",
        "\n",
        "    self.conv = nn.Conv2d(c_in, c_out, (filt, filt), stride=stride, padding=padding)\n",
        "    self.bn = nn.BatchNorm2d(c_out)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    n, c, h, w = x.shape\n",
        "    z = F.relu(self.bn(self.conv(x)))\n",
        "    return z\n",
        "\n",
        "# n1 - number of conv layers with kernel size (3, 3) - try to learn local\n",
        "# n2 - number of conv layers with kernel size (9, 9) - try to learn global\n",
        "# c_mid - number of kernels in conv layers\n",
        "class SudokuNet(nn.Module):\n",
        "  # !!! c_out should be 10 !!!\n",
        "  def __init__(self, n, n2, c_mid, c_in=1, c_out=10):\n",
        "    super(SudokuNet, self).__init__()\n",
        "    self.conv1 = ConvNet(c_in, c_mid)\n",
        "\n",
        "    self.seq = nn.Sequential()\n",
        "    for i in range(n):\n",
        "      self.seq.add_module(str(i), ConvNet(c_mid, c_mid, 3, 1, 1))\n",
        "\n",
        "    self.seq2 = nn.Sequential()\n",
        "    for i in range(n2):\n",
        "      self.seq2.add_module(str(i), ConvNet(c_mid, c_mid, 9, 1, 4))\n",
        "\n",
        "\n",
        "    self.convLast = nn.Conv2d(c_mid, c_out, (3,3), stride=1, padding=1)\n",
        "    self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "    z = self.conv1(x)\n",
        "    z = self.seq(z)\n",
        "    z = self.seq2(z)\n",
        "    z = self.logsoftmax(self.convLast(z))\n",
        "    return z\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jjA5bI4aVC0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get accuracy in range [start, end) with batch_size\n",
        "# change start/end to reduce running time\n",
        "# choose wisely, so that |train| : |test| = 9 : 1 (or 99 : 1)\n",
        "def get_accuracy(model, batch_size, start, end):\n",
        "    model.train(mode=False)\n",
        "\n",
        "    total_samples = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for i in range(start, end, batch_size):\n",
        "        x = quizes[i:i+batch_size]\n",
        "        y = solutions[i:i+batch_size]\n",
        "        x = x[:, np.newaxis]\n",
        "\n",
        "        X, y = torch.from_numpy(x), torch.from_numpy(y)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            X = X.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "        y_ = model(X)\n",
        "        _, y_ = torch.max(y_, axis=1)\n",
        "        \n",
        "        total_samples += 81 * batch_size\n",
        "        sum_ = torch.sum(torch.eq(y_, y).type(torch.FloatTensor))\n",
        "        total_correct += sum_.item()\n",
        "        print(f'batch: {i}, correct: [{int(sum_.item())}/{81*batch_size}]')\n",
        "\n",
        "    return total_correct / total_samples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXaT3OGNahmg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e50e7c34-b098-4a14-8eff-08dfddb54f2e"
      },
      "source": [
        "n = 10\n",
        "n2 = 0\n",
        "c_mid=100\n",
        "model = SudokuNet(n=n, n2=n2, c_mid=c_mid)\n",
        "if torch.cuda.is_available():\n",
        "    print(\"cuda\")\n",
        "    model.cuda()\n",
        "else:\n",
        "    print(\"cpu\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdpPqQcpaiUN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "962d8f72-ab0d-4cb4-e931-f1dffad5f520"
      },
      "source": [
        "# load model from Sudoku_train.ipynb\n",
        "checkpoint = torch.load(\"/content/drive/My Drive/Colab Notebooks/model_\" + str(n) + \"_\" + str(n2) + \"_\" + str(c_mid) + \".tar\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S9HVo5Zta-yT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "9b5da896-c0c6-4e27-ef0b-66e61645a07c"
      },
      "source": [
        "accuracy = get_accuracy(model, 1, 0, 30)\n",
        "print(f\"Total accuracy: {accuracy} on 30 tests\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch: 0, correct: [78/81]\n",
            "batch: 1, correct: [77/81]\n",
            "batch: 2, correct: [77/81]\n",
            "batch: 3, correct: [72/81]\n",
            "batch: 4, correct: [70/81]\n",
            "batch: 5, correct: [76/81]\n",
            "batch: 6, correct: [54/81]\n",
            "batch: 7, correct: [60/81]\n",
            "batch: 8, correct: [57/81]\n",
            "batch: 9, correct: [60/81]\n",
            "batch: 10, correct: [55/81]\n",
            "batch: 11, correct: [48/81]\n",
            "batch: 12, correct: [62/81]\n",
            "batch: 13, correct: [60/81]\n",
            "batch: 14, correct: [65/81]\n",
            "batch: 15, correct: [51/81]\n",
            "batch: 16, correct: [58/81]\n",
            "batch: 17, correct: [54/81]\n",
            "batch: 18, correct: [55/81]\n",
            "batch: 19, correct: [60/81]\n",
            "batch: 20, correct: [62/81]\n",
            "batch: 21, correct: [58/81]\n",
            "batch: 22, correct: [53/81]\n",
            "batch: 23, correct: [51/81]\n",
            "batch: 24, correct: [68/81]\n",
            "batch: 25, correct: [70/81]\n",
            "batch: 26, correct: [57/81]\n",
            "batch: 27, correct: [60/81]\n",
            "batch: 28, correct: [68/81]\n",
            "batch: 29, correct: [72/81]\n",
            "Total accuracy: 0.7687242798353909 on 30 tests\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_b8CfkdetfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}